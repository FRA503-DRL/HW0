{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 1: Take a Look at Cartpole Rl Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. According to the tutorials, if we want to edit the environment configuration, action space, observation space, reward function, or termination condition of the Isaac-Cartpole-v0 task, which file should we look at, and where is each part located?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source code:** https://github.com/isaac-sim/IsaacLab/blob/main/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/classic/cartpole/cartpole_env_cfg.py\n",
    "\n",
    "We should look at cartpole_env_cfg.py that locate in Home/IsaacLab/blob/main/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/classic/cartpole/cartpole_env_cfg.py and each part located\n",
    "\n",
    "**Environment configuration** in line 157-181\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@configclass\n",
    "class CartpoleEnvCfg(ManagerBasedRLEnvCfg):\n",
    "    \"\"\"Configuration for the cartpole environment.\"\"\"\n",
    "\n",
    "    # Scene settings\n",
    "    scene: CartpoleSceneCfg = CartpoleSceneCfg(num_envs=4096, env_spacing=4.0)\n",
    "    # Basic settings\n",
    "    observations: ObservationsCfg = ObservationsCfg()\n",
    "    actions: ActionsCfg = ActionsCfg()\n",
    "    events: EventCfg = EventCfg()\n",
    "    # MDP settings\n",
    "    rewards: RewardsCfg = RewardsCfg()\n",
    "    terminations: TerminationsCfg = TerminationsCfg()\n",
    "\n",
    "    # Post initialization\n",
    "    def __post_init__(self) -> None:\n",
    "        \"\"\"Post initialization.\"\"\"\n",
    "        # general settings\n",
    "        self.decimation = 2\n",
    "        self.episode_length_s = 5\n",
    "        # viewer settings\n",
    "        self.viewer.eye = (8.0, 0.0, 5.0)\n",
    "        # simulation settings\n",
    "        self.sim.dt = 1 / 120\n",
    "        self.sim.render_interval = self.decimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action space** in line 58-62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@configclass\n",
    "class ActionsCfg:\n",
    "    \"\"\"Action specifications for the MDP.\"\"\"\n",
    "\n",
    "    joint_effort = mdp.JointEffortActionCfg(asset_name=\"robot\", joint_names=[\"slider_to_cart\"], scale=100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation space** in line 65-85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@configclass\n",
    "class ObservationsCfg:\n",
    "    \"\"\"Observation specifications for the MDP.\"\"\"\n",
    "\n",
    "    @configclass\n",
    "    class PolicyCfg(ObsGroup):\n",
    "        \"\"\"Observations for policy group.\"\"\"\n",
    "\n",
    "        # observation terms (order preserved)\n",
    "        joint_pos_rel = ObsTerm(func=mdp.joint_pos_rel)\n",
    "        joint_vel_rel = ObsTerm(func=mdp.joint_vel_rel)\n",
    "\n",
    "        def __post_init__(self) -> None:\n",
    "            self.enable_corruption = False\n",
    "            self.concatenate_terms = True\n",
    "\n",
    "    # observation groups\n",
    "    policy: PolicyCfg = PolicyCfg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reward function** in line 111-136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@configclass\n",
    "class RewardsCfg:\n",
    "    \"\"\"Reward terms for the MDP.\"\"\"\n",
    "\n",
    "    # (1) Constant running reward\n",
    "    alive = RewTerm(func=mdp.is_alive, weight=1.0)\n",
    "    # (2) Failure penalty\n",
    "    terminating = RewTerm(func=mdp.is_terminated, weight=-2.0)\n",
    "    # (3) Primary task: keep pole upright\n",
    "    pole_pos = RewTerm(\n",
    "        func=mdp.joint_pos_target_l2,\n",
    "        weight=-1.0,\n",
    "        params={\"asset_cfg\": SceneEntityCfg(\"robot\", joint_names=[\"cart_to_pole\"]), \"target\": 0.0},\n",
    "    )\n",
    "    # (4) Shaping tasks: lower cart velocity\n",
    "    cart_vel = RewTerm(\n",
    "        func=mdp.joint_vel_l1,\n",
    "        weight=-0.01,\n",
    "        params={\"asset_cfg\": SceneEntityCfg(\"robot\", joint_names=[\"slider_to_cart\"])},\n",
    "    )\n",
    "    # (5) Shaping tasks: lower pole angular velocity\n",
    "    pole_vel = RewTerm(\n",
    "        func=mdp.joint_vel_l1,\n",
    "        weight=-0.005,\n",
    "        params={\"asset_cfg\": SceneEntityCfg(\"robot\", joint_names=[\"cart_to_pole\"])},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Termination condition** in line 139-149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@configclass\n",
    "class TerminationsCfg:\n",
    "    \"\"\"Termination terms for the MDP.\"\"\"\n",
    "\n",
    "    # (1) Time out\n",
    "    time_out = DoneTerm(func=mdp.time_out, time_out=True)\n",
    "    # (2) Cart out of bounds\n",
    "    cart_out_of_bounds = DoneTerm(\n",
    "        func=mdp.joint_pos_out_of_manual_limit,\n",
    "        params={\"asset_cfg\": SceneEntityCfg(\"robot\", joint_names=[\"slider_to_cart\"]), \"bounds\": (-3.0, 3.0)},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What are the action space and observation space for an agent defined in the Isaac-Cartpole-v0 task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action space is torque\n",
    "from line 58-62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@configclass\n",
    "class ActionsCfg:\n",
    "    \"\"\"Action specifications for the MDP.\"\"\"\n",
    "\n",
    "    joint_effort = mdp.JointEffortActionCfg(asset_name=\"robot\", joint_names=[\"slider_to_cart\"], scale=100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation space is position and velocity from line 65-82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@configclass\n",
    "class ObservationsCfg:\n",
    "    \"\"\"Observation specifications for the MDP.\"\"\"\n",
    "\n",
    "    @configclass\n",
    "    class PolicyCfg(ObsGroup):\n",
    "        \"\"\"Observations for policy group.\"\"\"\n",
    "\n",
    "        # observation terms (order preserved)\n",
    "        joint_pos_rel = ObsTerm(func=mdp.joint_pos_rel)\n",
    "        joint_vel_rel = ObsTerm(func=mdp.joint_vel_rel)\n",
    "\n",
    "        def __post_init__(self) -> None:\n",
    "            self.enable_corruption = False\n",
    "            self.concatenate_terms = True\n",
    "\n",
    "    # observation groups\n",
    "    policy: PolicyCfg = PolicyCfg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. How can episodes in the Isaac-Cartpole-v0 task be terminated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have 2 situations: in line 139-149\n",
    "1. Time out\n",
    "\n",
    "time_out = DoneTerm(func=mdp.time_out, time_out=True)\n",
    "\n",
    "2. Cart out of bounds\n",
    "\n",
    "cart_out_of_bounds = DoneTerm(\n",
    "        func=mdp.joint_pos_out_of_manual_limit,\n",
    "        params={\"asset_cfg\": SceneEntityCfg(\"robot\", joint_names=[\"slider_to_cart\"]), \"bounds\": (-3.0, 3.0)},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@configclass\n",
    "class TerminationsCfg:\n",
    "    \"\"\"Termination terms for the MDP.\"\"\"\n",
    "\n",
    "    # (1) Time out\n",
    "    time_out = DoneTerm(func=mdp.time_out, time_out=True)\n",
    "    # (2) Cart out of bounds\n",
    "    cart_out_of_bounds = DoneTerm(\n",
    "        func=mdp.joint_pos_out_of_manual_limit,\n",
    "        params={\"asset_cfg\": SceneEntityCfg(\"robot\", joint_names=[\"slider_to_cart\"]), \"bounds\": (-3.0, 3.0)},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. How many reward terms are used to train an agent in the Isaac-Cartpole-v0 task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 reward terms line 111-136\n",
    "\n",
    "1. Constant running reward เงื่อนไช\n",
    "2. Failure penalty\n",
    "3. Primary task: keep pole upright\n",
    "4. Shaping tasks: lower cart velocity\n",
    "5. Shaping tasks: lower pole angular velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@configclass\n",
    "class RewardsCfg:\n",
    "    \"\"\"Reward terms for the MDP.\"\"\"\n",
    "\n",
    "    # (1) Constant running reward\n",
    "    alive = RewTerm(func=mdp.is_alive, weight=1.0)\n",
    "    # (2) Failure penalty\n",
    "    terminating = RewTerm(func=mdp.is_terminated, weight=-2.0)\n",
    "    # (3) Primary task: keep pole upright\n",
    "    pole_pos = RewTerm(\n",
    "        func=mdp.joint_pos_target_l2,\n",
    "        weight=-1.0,\n",
    "        params={\"asset_cfg\": SceneEntityCfg(\"robot\", joint_names=[\"cart_to_pole\"]), \"target\": 0.0},\n",
    "    )\n",
    "    # (4) Shaping tasks: lower cart velocity\n",
    "    cart_vel = RewTerm(\n",
    "        func=mdp.joint_vel_l1,\n",
    "        weight=-0.01,\n",
    "        params={\"asset_cfg\": SceneEntityCfg(\"robot\", joint_names=[\"slider_to_cart\"])},\n",
    "    )\n",
    "    # (5) Shaping tasks: lower pole angular velocity\n",
    "    pole_vel = RewTerm(\n",
    "        func=mdp.joint_vel_l1,\n",
    "        weight=-0.005,\n",
    "        params={\"asset_cfg\": SceneEntityCfg(\"robot\", joint_names=[\"cart_to_pole\"])},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 2: Playing with Cartpole Rl Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us adjust the weight of each reward term specified in the Isaac-Cartpole-v0 task and train the agent. Which results will be affected by this adjustment, and why? Submit the answers.\n",
    "\n",
    "You may further explore by modifying other aspects, such as the agent's action space, observation space, and termination conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 3: Mapping RL Fundamentals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is reinforcement learning and its components according to your understanding? Giving examples of each component according to the diagram consider the Cartpole problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is the difference between the reward, return, and the value function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Consider policy, state, value function, and model as mathematical functions, what would each one take as input and output?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
